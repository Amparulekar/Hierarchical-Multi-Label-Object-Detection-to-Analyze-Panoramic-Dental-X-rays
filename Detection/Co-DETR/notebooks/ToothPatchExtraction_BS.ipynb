{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zuTOsvjvBwzE"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzeCVifRITCQ"
      },
      "source": [
        "# Load Data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43FWgi1jB59L",
        "outputId": "260e9913-8101-4f15-c84f-32e7ff999044"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['images', 'annotations', 'categories_1', 'categories_2', 'categories_3'])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# filename will contain full address of qed.json given by the dataset\n",
        "# CHANGE\n",
        "filename = f\"/raid/infolab/bhavyakohli/mmdet/mmdetection/data/training_data/Compressed_training_data/quadrant_enumeration_disease/train_quadrant_enumeration_disease.json\"\n",
        "f = json.load(open(filename))\n",
        "\n",
        "f.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0Wjjqq3Kseu",
        "outputId": "759eb27b-8c8e-45a0-9db5-bd1647cdd873"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'id': 0, 'name': 'Impacted', 'supercategory': 'Impacted'},\n",
              " {'id': 1, 'name': 'Caries', 'supercategory': 'Caries'},\n",
              " {'id': 2, 'name': 'Periapical Lesion', 'supercategory': 'Periapical Lesion'},\n",
              " {'id': 3, 'name': 'Deep Caries', 'supercategory': 'Deep Caries'}]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f['categories_3']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXaByp7HJnF5",
        "outputId": "1147cce1-29f7-428f-d05e-20023a717b48"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['iscrowd', 'image_id', 'bbox', 'segmentation', 'id', 'area', 'category_id_1', 'category_id_2', 'category_id_3'])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f['annotations'][0].keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IwLyrm94C2H6"
      },
      "outputs": [],
      "source": [
        "# take annotations from the qed.jsona and convert it into a sorted dataframe\n",
        "\n",
        "annos = pd.DataFrame.from_dict(f['annotations'], orient='columns')\n",
        "annos.drop(columns = [\"iscrowd\", \"segmentation\", \"area\"], axis=1, inplace=True)\n",
        "annos.sort_values(by = [\"image_id\"], inplace = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jD3w_sx7SoJe"
      },
      "source": [
        "# Performing some checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FeEh6EcRVUJ"
      },
      "outputs": [],
      "source": [
        "#annots = [{\"iscrowd\": 0, \"image_id\": 1, \"bbox\": [542.0, 698.0, 220.0, 271.0], \"segmentation\": [[621, 703, 573, 744, 542, 885, 580, 945, 650, 969, 711, 883, 762, 807, 748, 741, 649, 698]], \"id\": 1, \"area\": 39683, \"category_id_1\": 3, \"category_id_2\": 7, \"category_id_3\": 0}, {\"iscrowd\": 0, \"image_id\": 1, \"bbox\": [1952.0, 693.0, 177.0, 270.0], \"segmentation\": [[2045, 693, 2109, 734, 2129, 915, 2047, 963, 2009, 909, 1973, 851, 1955, 782, 1952, 730, 2000, 702]], \"id\": 2, \"area\": 33301, \"category_id_1\": 2, \"category_id_2\": 7, \"category_id_3\": 0}, {\"iscrowd\": 0, \"image_id\": 1, \"bbox\": [675.0, 708.0, 243.0, 300.0], \"segmentation\": [[784, 711, 754, 746, 737, 821, 678, 916, 675, 986, 690, 1003, 727, 1008, 787, 998, 851, 925, 885, 857, 918, 807, 916, 763, 882, 720, 827, 708]], \"id\": 3, \"area\": 45758, \"category_id_1\": 3, \"category_id_2\": 6, \"category_id_3\": 1}, {\"iscrowd\": 0, \"image_id\": 1, \"bbox\": [1463.0, 725.0, 98.0, 425.0], \"segmentation\": [[1464, 749, 1513, 725, 1550, 760, 1555, 798, 1548, 887, 1561, 1147, 1510, 1150, 1488, 1039, 1463, 873, 1463, 778]], \"id\": 4, \"area\": 30985, \"category_id_1\": 2, \"category_id_2\": 2, \"category_id_3\": 1}, {\"iscrowd\": 0, \"image_id\": 1, \"bbox\": [1536.0, 753.0, 103.0, 381.0], \"segmentation\": [[1543, 796, 1590, 753, 1622, 796, 1629, 840, 1623, 890, 1639, 1111, 1596, 1134, 1565, 1077, 1544, 974, 1536, 852, 1536, 805]], \"id\": 5, \"area\": 28044, \"category_id_1\": 2, \"category_id_2\": 3, \"category_id_3\": 1}, {\"iscrowd\": 0, \"image_id\": 1, \"bbox\": [1600.0, 762.0, 122.0, 337.0], \"segmentation\": [[1605, 797, 1646, 762, 1684, 785, 1701, 852, 1722, 1095, 1684, 1099, 1645, 1030, 1621, 884, 1600, 825]], \"id\": 6, \"area\": 24348, \"category_id_1\": 2, \"category_id_2\": 4, \"category_id_3\": 1}, {\"iscrowd\": 0, \"image_id\": 1, \"bbox\": [1701.0, 371.0, 145.0, 290.0], \"segmentation\": [[1716, 409, 1711, 543, 1701, 604, 1713, 651, 1770, 661, 1827, 636, 1831, 531, 1846, 396, 1835, 371, 1759, 371, 1730, 384]], \"id\": 7, \"area\": 34145, \"category_id_1\": 1, \"category_id_2\": 5, \"category_id_3\": 1}, {\"iscrowd\": 0, \"image_id\": 1, \"bbox\": [779.0, 376.0, 132.0, 317.0], \"segmentation\": [[779, 487, 791, 631, 800, 680, 822, 692, 894, 693, 911, 654, 910, 594, 887, 535, 856, 396, 816, 376, 779, 406]], \"id\": 8, \"area\": 31064, \"category_id_1\": 0, \"category_id_2\": 6, \"category_id_3\": 1}, {\"iscrowd\": 0, \"image_id\": 1, \"bbox\": [1667.0, 723.0, 237.0, 356.0], \"segmentation\": [[1667, 784, 1689, 747, 1741, 753, 1802, 723, 1816, 767, 1833, 873, 1904, 1023, 1784, 1079, 1725, 996, 1694, 878, 1668, 808]], \"id\": 9, \"area\": 46556, \"category_id_1\": 2, \"category_id_2\": 5, \"category_id_3\": 1}, {\"iscrowd\": 0, \"image_id\": 1, \"bbox\": [1806.0, 696.0, 237.0, 308.0], \"segmentation\": [[1843, 724, 1806, 745, 1807, 800, 1857, 901, 1921, 998, 2011, 1004, 2043, 959, 1999, 871, 1969, 803, 1950, 734, 1908, 696]], \"id\": 10, \"area\": 42235, \"category_id_1\": 2, \"category_id_2\": 6, \"category_id_3\": 1}, {\"iscrowd\": 0, \"image_id\": 1, \"bbox\": [1405.1948051948052, 724.6753246753246, 75.32467532467535, 353.2467532467533], \"segmentation\": [[1418, 724, 1476, 729, 1466, 841, 1477, 941, 1480, 1075, 1419, 1077, 1409, 931, 1405, 790]], \"id\": 11, \"area\": 22286, \"category_id_1\": 2, \"category_id_2\": 1, \"category_id_3\": 2}, {\"iscrowd\": 0, \"image_id\": 1, \"bbox\": [1344.155844155844, 720.7792207792207, 77.92207792207796, 385.71428571428567], \"segmentation\": [[1414, 720, 1403, 909, 1422, 1089, 1346, 1106, 1346, 887, 1344, 725]], \"id\": 12, \"area\": 24371, \"category_id_1\": 2, \"category_id_2\": 0, \"category_id_3\": 2}, {\"iscrowd\": 0, \"image_id\": 1, \"bbox\": [1288.3116883116884, 723.3766233766233, 62.33766233766232, 387.0129870129871], \"segmentation\": [[1344, 728, 1350, 1110, 1290, 1092, 1290, 962, 1288, 723]], \"id\": 13, \"area\": 21469, \"category_id_1\": 3, \"category_id_2\": 0, \"category_id_3\": 2}]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "3cN5m4aARRop",
        "outputId": "94500615-ce6a-4bcb-c920-38838ac6dcb6"
      },
      "outputs": [],
      "source": [
        "# image = cv2.imread(\"train_673.png\")\n",
        "# for dic in annots:\n",
        "#   x_min, y_min, width, height = dic['bbox'][:]\n",
        "\n",
        "#   x_max = x_min + width\n",
        "#   y_max = y_min + height\n",
        "\n",
        "#   if dic[\"category_id_1\"] == 0:\n",
        "#     color = (255, 0, 0)    #red\n",
        "#   elif dic[\"category_id_1\"] == 1:\n",
        "#     color = (0, 255, 0)   #green\n",
        "#   elif dic[\"category_id_1\"] == 2:\n",
        "#     color = (0, 0, 255)   #blue\n",
        "#   elif dic[\"category_id_1\"] == 3:\n",
        "#     color = (0, 0,0)      #black\n",
        "#   thickness = 5\n",
        "#   cv2.rectangle(image, (int(x_min), int(y_min)), (int(x_max), int(y_max)), color, thickness)\n",
        "\n",
        "# plt.imshow(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load the Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-20 05:07:18,838 - mmcv - INFO - initialize RPNHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}\n",
            "2024-04-20 05:07:18,849 - mmcv - INFO - \n",
            "rpn_conv.weight - torch.Size([256, 256, 3, 3]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2024-04-20 05:07:18,850 - mmcv - INFO - \n",
            "rpn_conv.bias - torch.Size([256]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2024-04-20 05:07:18,851 - mmcv - INFO - \n",
            "rpn_cls.weight - torch.Size([9, 256, 1, 1]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2024-04-20 05:07:18,852 - mmcv - INFO - \n",
            "rpn_cls.bias - torch.Size([9]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2024-04-20 05:07:18,853 - mmcv - INFO - \n",
            "rpn_reg.weight - torch.Size([36, 256, 1, 1]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2024-04-20 05:07:18,853 - mmcv - INFO - \n",
            "rpn_reg.bias - torch.Size([36]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2024-04-20 05:07:18,935 - mmcv - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]\n",
            "2024-04-20 05:07:19,111 - mmcv - INFO - \n",
            "bbox_head.fc_cls.weight - torch.Size([5, 1024]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2024-04-20 05:07:19,114 - mmcv - INFO - \n",
            "bbox_head.fc_cls.bias - torch.Size([5]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2024-04-20 05:07:19,115 - mmcv - INFO - \n",
            "bbox_head.fc_reg.weight - torch.Size([16, 1024]): \n",
            "NormalInit: mean=0, std=0.001, bias=0 \n",
            " \n",
            "2024-04-20 05:07:19,115 - mmcv - INFO - \n",
            "bbox_head.fc_reg.bias - torch.Size([16]): \n",
            "NormalInit: mean=0, std=0.001, bias=0 \n",
            " \n",
            "2024-04-20 05:07:19,116 - mmcv - INFO - \n",
            "bbox_head.shared_fcs.0.weight - torch.Size([1024, 12544]): \n",
            "XavierInit: gain=1, distribution=uniform, bias=0 \n",
            " \n",
            "2024-04-20 05:07:19,117 - mmcv - INFO - \n",
            "bbox_head.shared_fcs.0.bias - torch.Size([1024]): \n",
            "XavierInit: gain=1, distribution=uniform, bias=0 \n",
            " \n",
            "2024-04-20 05:07:19,117 - mmcv - INFO - \n",
            "bbox_head.shared_fcs.1.weight - torch.Size([1024, 1024]): \n",
            "XavierInit: gain=1, distribution=uniform, bias=0 \n",
            " \n",
            "2024-04-20 05:07:19,118 - mmcv - INFO - \n",
            "bbox_head.shared_fcs.1.bias - torch.Size([1024]): \n",
            "XavierInit: gain=1, distribution=uniform, bias=0 \n",
            " \n",
            "2024-04-20 05:07:19,134 - mmcv - INFO - initialize CoATSSHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01, 'override': {'type': 'Normal', 'name': 'atss_cls', 'std': 0.01, 'bias_prob': 0.01}}\n",
            "2024-04-20 05:07:19,148 - mmcv - INFO - \n",
            "cls_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2024-04-20 05:07:19,148 - mmcv - INFO - \n",
            "cls_convs.0.gn.weight - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
            " \n",
            "2024-04-20 05:07:19,149 - mmcv - INFO - \n",
            "cls_convs.0.gn.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
            " \n",
            "2024-04-20 05:07:19,149 - mmcv - INFO - \n",
            "reg_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2024-04-20 05:07:19,149 - mmcv - INFO - \n",
            "reg_convs.0.gn.weight - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
            " \n",
            "2024-04-20 05:07:19,150 - mmcv - INFO - \n",
            "reg_convs.0.gn.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
            " \n",
            "2024-04-20 05:07:19,150 - mmcv - INFO - \n",
            "atss_cls.weight - torch.Size([4, 256, 3, 3]): \n",
            "NormalInit: mean=0, std=0.01, bias=-4.59511985013459 \n",
            " \n",
            "2024-04-20 05:07:19,151 - mmcv - INFO - \n",
            "atss_cls.bias - torch.Size([4]): \n",
            "NormalInit: mean=0, std=0.01, bias=-4.59511985013459 \n",
            " \n",
            "2024-04-20 05:07:19,151 - mmcv - INFO - \n",
            "atss_reg.weight - torch.Size([4, 256, 3, 3]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2024-04-20 05:07:19,151 - mmcv - INFO - \n",
            "atss_reg.bias - torch.Size([4]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2024-04-20 05:07:19,152 - mmcv - INFO - \n",
            "atss_centerness.weight - torch.Size([1, 256, 3, 3]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2024-04-20 05:07:19,152 - mmcv - INFO - \n",
            "atss_centerness.bias - torch.Size([1]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2024-04-20 05:07:19,152 - mmcv - INFO - \n",
            "scales.0.scale - torch.Size([]): \n",
            "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
            " \n",
            "2024-04-20 05:07:19,153 - mmcv - INFO - \n",
            "scales.1.scale - torch.Size([]): \n",
            "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
            " \n",
            "2024-04-20 05:07:19,153 - mmcv - INFO - \n",
            "scales.2.scale - torch.Size([]): \n",
            "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
            " \n",
            "2024-04-20 05:07:19,153 - mmcv - INFO - \n",
            "scales.3.scale - torch.Size([]): \n",
            "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
            " \n",
            "2024-04-20 05:07:19,154 - mmcv - INFO - \n",
            "scales.4.scale - torch.Size([]): \n",
            "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
            " \n",
            "2024-04-20 05:07:19,154 - mmcv - INFO - \n",
            "scales.5.scale - torch.Size([]): \n",
            "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
            " \n",
            "2024-04-20 05:07:22,585 - mmcv - INFO - initialize RPNHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}\n",
            "2024-04-20 05:07:22,596 - mmcv - INFO - \n",
            "rpn_conv.weight - torch.Size([256, 256, 3, 3]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2024-04-20 05:07:22,597 - mmcv - INFO - \n",
            "rpn_conv.bias - torch.Size([256]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2024-04-20 05:07:22,598 - mmcv - INFO - \n",
            "rpn_cls.weight - torch.Size([9, 256, 1, 1]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2024-04-20 05:07:22,598 - mmcv - INFO - \n",
            "rpn_cls.bias - torch.Size([9]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2024-04-20 05:07:22,599 - mmcv - INFO - \n",
            "rpn_reg.weight - torch.Size([36, 256, 1, 1]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2024-04-20 05:07:22,599 - mmcv - INFO - \n",
            "rpn_reg.bias - torch.Size([36]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2024-04-20 05:07:22,667 - mmcv - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]\n",
            "2024-04-20 05:07:22,869 - mmcv - INFO - \n",
            "bbox_head.fc_cls.weight - torch.Size([9, 1024]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2024-04-20 05:07:22,870 - mmcv - INFO - \n",
            "bbox_head.fc_cls.bias - torch.Size([9]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2024-04-20 05:07:22,870 - mmcv - INFO - \n",
            "bbox_head.fc_reg.weight - torch.Size([32, 1024]): \n",
            "NormalInit: mean=0, std=0.001, bias=0 \n",
            " \n",
            "2024-04-20 05:07:22,871 - mmcv - INFO - \n",
            "bbox_head.fc_reg.bias - torch.Size([32]): \n",
            "NormalInit: mean=0, std=0.001, bias=0 \n",
            " \n",
            "2024-04-20 05:07:22,871 - mmcv - INFO - \n",
            "bbox_head.shared_fcs.0.weight - torch.Size([1024, 12544]): \n",
            "XavierInit: gain=1, distribution=uniform, bias=0 \n",
            " \n",
            "2024-04-20 05:07:22,872 - mmcv - INFO - \n",
            "bbox_head.shared_fcs.0.bias - torch.Size([1024]): \n",
            "XavierInit: gain=1, distribution=uniform, bias=0 \n",
            " \n",
            "2024-04-20 05:07:22,872 - mmcv - INFO - \n",
            "bbox_head.shared_fcs.1.weight - torch.Size([1024, 1024]): \n",
            "XavierInit: gain=1, distribution=uniform, bias=0 \n",
            " \n",
            "2024-04-20 05:07:22,872 - mmcv - INFO - \n",
            "bbox_head.shared_fcs.1.bias - torch.Size([1024]): \n",
            "XavierInit: gain=1, distribution=uniform, bias=0 \n",
            " \n",
            "2024-04-20 05:07:22,890 - mmcv - INFO - initialize CoATSSHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01, 'override': {'type': 'Normal', 'name': 'atss_cls', 'std': 0.01, 'bias_prob': 0.01}}\n",
            "2024-04-20 05:07:22,908 - mmcv - INFO - \n",
            "cls_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2024-04-20 05:07:22,908 - mmcv - INFO - \n",
            "cls_convs.0.gn.weight - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
            " \n",
            "2024-04-20 05:07:22,908 - mmcv - INFO - \n",
            "cls_convs.0.gn.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
            " \n",
            "2024-04-20 05:07:22,909 - mmcv - INFO - \n",
            "reg_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2024-04-20 05:07:22,909 - mmcv - INFO - \n",
            "reg_convs.0.gn.weight - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
            " \n",
            "2024-04-20 05:07:22,910 - mmcv - INFO - \n",
            "reg_convs.0.gn.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
            " \n",
            "2024-04-20 05:07:22,910 - mmcv - INFO - \n",
            "atss_cls.weight - torch.Size([8, 256, 3, 3]): \n",
            "NormalInit: mean=0, std=0.01, bias=-4.59511985013459 \n",
            " \n",
            "2024-04-20 05:07:22,911 - mmcv - INFO - \n",
            "atss_cls.bias - torch.Size([8]): \n",
            "NormalInit: mean=0, std=0.01, bias=-4.59511985013459 \n",
            " \n",
            "2024-04-20 05:07:22,912 - mmcv - INFO - \n",
            "atss_reg.weight - torch.Size([4, 256, 3, 3]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2024-04-20 05:07:22,912 - mmcv - INFO - \n",
            "atss_reg.bias - torch.Size([4]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2024-04-20 05:07:22,913 - mmcv - INFO - \n",
            "atss_centerness.weight - torch.Size([1, 256, 3, 3]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2024-04-20 05:07:22,913 - mmcv - INFO - \n",
            "atss_centerness.bias - torch.Size([1]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2024-04-20 05:07:22,914 - mmcv - INFO - \n",
            "scales.0.scale - torch.Size([]): \n",
            "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
            " \n",
            "2024-04-20 05:07:22,914 - mmcv - INFO - \n",
            "scales.1.scale - torch.Size([]): \n",
            "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
            " \n",
            "2024-04-20 05:07:22,914 - mmcv - INFO - \n",
            "scales.2.scale - torch.Size([]): \n",
            "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
            " \n",
            "2024-04-20 05:07:22,915 - mmcv - INFO - \n",
            "scales.3.scale - torch.Size([]): \n",
            "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
            " \n",
            "2024-04-20 05:07:22,915 - mmcv - INFO - \n",
            "scales.4.scale - torch.Size([]): \n",
            "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
            " \n",
            "2024-04-20 05:07:22,915 - mmcv - INFO - \n",
            "scales.5.scale - torch.Size([]): \n",
            "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
            " \n"
          ]
        }
      ],
      "source": [
        "import sys, os\n",
        "sys.path.append(\"/raid/infolab/bhavyakohli/mmdet/Co-DETR/\")\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n",
        "warnings.filterwarnings(action='ignore', category=UserWarning)\n",
        "\n",
        "from tqdm import tqdm\n",
        "from mmdet.apis import *\n",
        "\n",
        "# CHANGE\n",
        "# Setup a checkpoint file to load\n",
        "m1_checkpoint = '../experiments/wave3_quadrant/latest.pth'\n",
        "m1_configpath = '../experiments/wave3_quadrant/co_dino_5scale_r50_1x_coco_quadrant.py'\n",
        "\n",
        "model1 = init_detector(m1_configpath, m1_checkpoint)\n",
        "\n",
        "m2_checkpoint = '../experiments/wave3_enumeration/latest.pth'\n",
        "m2_configpath = '../experiments/wave3_enumeration/co_dino_5scale_r50_1x_coco_enumeration.py'\n",
        "\n",
        "model2 = init_detector(m2_configpath, m2_checkpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALRuqnD-IcKs"
      },
      "source": [
        "# Run through M1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "QOdwSf-FC990"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "705"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# we read images in our third dataset here\n",
        "\n",
        "# CHANGE\n",
        "image_filepath = \"/raid/infolab/bhavyakohli/mmdet/mmdetection/data/training_data/Compressed_training_data/quadrant_enumeration_disease/xrays/\"  \n",
        "# where images are stored\n",
        "images = [image_filepath+imageinfo['file_name'] for imageinfo in f['images']]\n",
        "len(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0oqEEISoDAfg"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 705/705 [01:11<00:00,  9.83it/s]\n"
          ]
        }
      ],
      "source": [
        "# obtain results by running model1 on the images read in the previous block\n",
        "\n",
        "quad_results = []\n",
        "\n",
        "for image in tqdm(images):\n",
        "    result = inference_detector(model1, image)\n",
        "    result = [r[0][:-1] for r in result]\n",
        "    quad_results.append(result)\n",
        "\n",
        "# results has list of results for each input\n",
        "# each of these results have 4 Nx5 arrays (one for each quadrant)\n",
        "# the top 1x5 contains bboxes with highest confidence score\n",
        "# this contains topleft_x, topleft_y, bottomright_x, bottomright_y, score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "705"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(quad_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Ugx82KQUEsaY"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 705/705 [00:03<00:00, 208.91it/s]\n"
          ]
        }
      ],
      "source": [
        "# prep for q_patch storage\n",
        "# CHANGE\n",
        "qlocation = \"/raid/infolab/bhavyakohli/mmdet/mmdetection/data/training_data/Compressed_training_data/quadrant_enumeration_disease/qpatches/\"        \n",
        "# where to store patches\n",
        "os.makedirs(qlocation, exist_ok=True)\n",
        "qimagenames = []      # this will contain image names (WITHOUT the directory part)\n",
        "k = 0\n",
        "m = annos.shape[0]\n",
        "# begin iterations\n",
        "for i in tqdm(range(len(images))):\n",
        "  photo = cv2.imread(images[i])\n",
        "  patches = [\"a\",\"a\",\"a\",\"a\"]\n",
        "  result = quad_results[i]\n",
        "  qbboxs = [[0],[0],[0],[0]]  \n",
        "  for j in range(4):\n",
        "    x_min, y_min, x_max, y_max = result[j]\n",
        "    # adjust for category mismatch in data\n",
        "    cat = j\n",
        "    if cat == 0:\n",
        "      cat = 1\n",
        "    elif cat == 1:\n",
        "      cat = 0\n",
        "    # patch extraction and flipping\n",
        "    x_min = max(0, int(x_min))\n",
        "    y_min = max(0, int(y_min))\n",
        "    x_max = min(photo.shape[1], int(x_max))\n",
        "    y_max = min(photo.shape[0], int(y_max))\n",
        "    patch = photo[y_min:y_max, x_min:x_max]\n",
        "    if cat == 1 or cat == 2:\n",
        "      patch = cv2.flip(patch, 1)\n",
        "    if cat == 2 or cat == 3:\n",
        "      patch = cv2.flip(patch, 0)\n",
        "    # saving the patch\n",
        "    id = i+1\n",
        "    filename = \"patch\"+\"_\"+str(id)+\"_\"+str(cat)+\".png\"\n",
        "    patches[cat] = filename\n",
        "    cv2.imwrite(qlocation+filename, patch)\n",
        "    qbboxs[cat] = [x_min, y_min, x_max-x_min, y_max-y_min]\n",
        "  qimagenames += patches\n",
        "  # adjusting annotations\n",
        "  while annos.iloc[k]['image_id'] == id:\n",
        "    quad = annos.iloc[k]['category_id_1']\n",
        "    qxmin, qymin, qwidth, qheight = qbboxs[quad]\n",
        "    x_min, y_min, width, height = annos.iloc[k]['bbox']\n",
        "    # print(k)\n",
        "    # print(id)\n",
        "    # print(quad)\n",
        "    # print(qbboxs[quad])\n",
        "    # print(annos.iloc[k]['bbox'])\n",
        "    x_min = max(0, x_min - qxmin)\n",
        "    y_min = max(0, y_min - qymin)\n",
        "    #flip the bbano\n",
        "    if quad == 1 or quad == 2:\n",
        "        x_min = max(0, qwidth - x_min)\n",
        "        x_min = max(0, x_min - width)\n",
        "    if quad == 2 or quad == 3:\n",
        "        y_min = max(0, qheight - y_min)\n",
        "        y_min = max(0, y_min - height)\n",
        "    #save the bbano \n",
        "    annos.iat[k,1] = [x_min, y_min, width, height]    #bbox is at column index 1\n",
        "    # print(annos.iat[k,1])\n",
        "    k+=1\n",
        "    if k==m:\n",
        "      break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQUgaj-lIinw"
      },
      "source": [
        "# Run through M2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# creating a full address to the images and running them through model2\n",
        "\n",
        "qimages = [qlocation+name for name in qimagenames]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "qeHVVKBFZX1R"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2820/2820 [05:03<00:00,  9.29it/s]\n"
          ]
        }
      ],
      "source": [
        "#enumresults = inference_detector(model2, qimages)\n",
        "\n",
        "enumresults = []\n",
        "for qimage in tqdm(qimages):\n",
        "    result = inference_detector(model2, qimage)\n",
        "    result = [r[0] for r in result]\n",
        "    enumresults.append(result)\n",
        "\n",
        "# results has list of results for each input\n",
        "# each of these results have 8 Nx5 arrays (one for each quadrant)\n",
        "# the top 1x5 contains bboxes with highest confidence score\n",
        "# this contains topleft_x, topleft_y, bottomright_x, bottomright_y, score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "X-UKgFX5Ct21"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2820/2820 [00:07<00:00, 365.60it/s]\n"
          ]
        }
      ],
      "source": [
        "# tooth patch extraction, pretty straightforward\n",
        "# iterating over the annos dataframe to check if the given tooth\n",
        "# has a category associated to it, if not, given cat3 = 4 (normal)\n",
        "# CHANGE\n",
        "toothlocation = \"/raid/infolab/bhavyakohli/mmdet/mmdetection/data/training_data/Compressed_training_data/quadrant_enumeration_disease/tpatches/\"        # where to store patches of teeth\n",
        "os.makedirs(toothlocation, exist_ok=True)\n",
        "# patch_size = (380, 550)   # width, height\n",
        "patch_size = (50, 70)   # width, height for compression level 3\n",
        "\n",
        "for i in tqdm(range(len(qimages))):\n",
        "  # load data\n",
        "  photo = cv2.imread(qimages[i])\n",
        "  name = qimagenames[i]\n",
        "  id, cat1 = name[6:-4].split('_')\n",
        "  selection1 = annos.loc[annos['image_id'] == int(id)]\n",
        "  #print(selection1)\n",
        "  exist = True\n",
        "  if selection1.shape[0] == 0:\n",
        "    exist = False\n",
        "  else:\n",
        "    #print('hey')\n",
        "    selection2 = selection1.loc[selection1['category_id_1'] == int(cat1)]\n",
        "    if selection2.shape[0] == 0:\n",
        "      exist = False\n",
        "\n",
        "  # collect unique results with decent scores\n",
        "  results = [res if res[-1]>=0.3 else [0] for res in enumresults[i]]\n",
        "  cat3 = [4]*8\n",
        "  for j in range(8):\n",
        "    if len(results[j]) > 1:\n",
        "      for k in range(j+1, 8):\n",
        "        if len(results[k]) > 1:\n",
        "          if (results[j][:-1] == results[k][:-1]).all():\n",
        "            if results[j][-1] >= results[k][-1]:\n",
        "              results[k] = [0]\n",
        "            else:\n",
        "              results[j] = [0]\n",
        "              break\n",
        "\n",
        "  # pre-existing bboxes replace the ones that came from the model\n",
        "  if exist:\n",
        "    for enum in range(8):\n",
        "      selection3 = selection2.loc[selection2['category_id_2'] == enum]\n",
        "      if selection3.shape[0] != 0:\n",
        "        #print(selection3)\n",
        "        #print(selection3.iloc[0]['bbox'])\n",
        "        cat3[enum] = selection3.iloc[0]['category_id_3']\n",
        "        #print(cat3[enum])\n",
        "        x_min, y_min, width, height = selection3.iloc[0]['bbox']\n",
        "        results[enum] = [x_min, y_min, x_min+width, y_min+height, 1.0]\n",
        "        #print(results[enum])\n",
        "\n",
        "  for j in range(8):\n",
        "    if len(results[j]) > 1:\n",
        "      x_min, y_min, x_max, y_max, score = results[j]\n",
        "      x_min = max(0, int(x_min))\n",
        "      y_min = max(0, int(y_min))\n",
        "      x_max = min(photo.shape[1], int(x_max))\n",
        "      y_max = min(photo.shape[0], int(y_max))        \n",
        "      patch = photo[y_min:y_max, x_min:x_max]\n",
        "      height = y_max - y_min\n",
        "      width = x_max - x_min\n",
        "\n",
        "      # Resize patch\n",
        "      toppad, bottompad, leftpad, rightpad = [0,0,0,0]\n",
        "      if height < patch_size[1]:\n",
        "        toppad = int((patch_size[1] - height)/2)\n",
        "        bottompad = int(patch_size[1] - height - toppad)\n",
        "      if width < patch_size[0]:\n",
        "        leftpad = int((patch_size[0] - width)/2)\n",
        "        rightpad = int(patch_size[0] - width - leftpad)\n",
        "      patch = cv2.copyMakeBorder(\n",
        "                patch, toppad, bottompad, leftpad, rightpad,\n",
        "                cv2.BORDER_CONSTANT, value=[0,0,0])\n",
        "      patch = cv2.resize(patch, patch_size, interpolation = cv2.INTER_AREA)\n",
        "\n",
        "      filename = \"patch\"+\"_\"+str(id)+\"_\"+str(cat1)+\"_\"+str(j)+\"_\"+str(cat3[j])+\".png\"\n",
        "      cv2.imwrite(toothlocation+filename, patch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "19170"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(os.listdir(toothlocation))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import os\n",
        "# count = [0]*705\n",
        "# given = [0]*705\n",
        "# for img in os.listdir('/raid/infolab/bhavyakohli/mmdet/mmdetection/data/training_data/quadrant-enumeration-disease/tpatches'):\n",
        "#     if img.split('.')[0][-1]!=str(4):\n",
        "#         id = img.split('.')[0].split('_')[-4]\n",
        "#         count[int(id) - 1] += 1\n",
        "# for i in range(705):\n",
        "#     given[i] = annos.loc[annos['image_id'] == i+1].shape[0]\n",
        "#     if given[i] != count[i]:\n",
        "#         print(i, given[i]-count[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Extra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# lt = [np.array([1,2,3]), [0], np.array([4,5,6]), np.array([7,8,9]), [0], np.array([0,4,6])]\n",
        "# for i in range(6):\n",
        "#     if len(lt[i])>1:\n",
        "#         print(lt[i])\n",
        "\n",
        "# type(lt[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6HV3poJHIR2m"
      },
      "outputs": [],
      "source": [
        "# # tooth patch extraction, pretty straightforward\n",
        "# # iterating over the annos dataframe to check if the given tooth\n",
        "# # has a category associated to it, if not, given cat3 = 4 (normal)\n",
        "\n",
        "# toothlocation = \"\"        # where to store patches of teeth\n",
        "# k=0                       # move through annos\n",
        "# m = annos.shape[0]\n",
        "# patch_size = (380, 550)   # width, height\n",
        "\n",
        "# for i in range(len(qimages)):\n",
        "#   photo = cv2.imread(qimages[i])\n",
        "#   name = qimagenames[i]\n",
        "#   id, cat1 = name[6:-4].split('_')\n",
        "\n",
        "#   for result in enumresults[i]:\n",
        "#     x_min, y_min, x_max, y_max, cat2 = result           # KOHLI NOTE: Second spot\n",
        "#     patch = photo[y_min:y_max, x_min:x_max]\n",
        "#     height = y_max - y_min\n",
        "#     width = x_max - x_min\n",
        "\n",
        "#     # Resize patch [image may be bigger than given patch_size :(]\n",
        "#     toppad, bottompad, leftpad, rightpad = [0,0,0,0]\n",
        "#     if height < patch_size[1]:\n",
        "#       toppad = int((patch_size[1] - height)/2)\n",
        "#       bottompad = int(patch_size[1] - height - toppad)\n",
        "#     if width < patch_size[0]:\n",
        "#       leftpad = int((patch_size[0] - width)/2)\n",
        "#       rightpad = int(patch_size[0] - width - leftpad)\n",
        "#     patch = cv2.copyMakeBorder(\n",
        "#               patch, toppad, bottompad, leftpad, rightpad,\n",
        "#               cv2.BORDER_CONSTANT, value=[0,0,0])\n",
        "#     patch = cv2.resize(patch, patch_size, interpolation = cv2.INTER_AREA)\n",
        "\n",
        "#     while annos.iloc[k]['image_id'] == id:\n",
        "#       while annos.iloc[k]['category_id_1'] == cat1:\n",
        "#         if annos.iloc[k]['category_id_2'] == cat2:\n",
        "#           cat3 = annos.iloc[k]['category_id_3']\n",
        "#           filename = toothlocation+\"patch\"+\"_\"+id+\"_\"+cat1+\"_\"+cat2+\"_\"+cat3+\".png\"\n",
        "#           cv2.imwrite(filename, patch)\n",
        "#           k += 1\n",
        "#           if k==m:\n",
        "#             break\n",
        "#         else:\n",
        "#           cat3 = 4\n",
        "#           filename = toothlocation+\"patch\"+\"_\"+id+\"_\"+cat1+\"_\"+cat2+\"_\"+cat3+\".png\"\n",
        "#           cv2.imwrite(filename, patch)\n",
        "#       if k==m:\n",
        "#         break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfi0BsLqTq_D",
        "outputId": "5609cfbc-61a3-4c4b-e224-ef797dd82b9c"
      },
      "outputs": [],
      "source": [
        "# strd = \"patch_234_5.png\"\n",
        "# strd[6:-4].split('_')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "jD3w_sx7SoJe"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
